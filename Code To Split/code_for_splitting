import lightning as L
import torch
import torchmetrics
import torchvision
from torch import nn
from torch.nn import functional as F, init
from torch.utils.data import DataLoader
from torchmetrics import ConfusionMatrix
from torchvision import transforms, datasets
from torchvision.transforms import ToTensor


class Model(L.LightningModule):
    def __init__(self, batch_size, learning_rate, num_classes, epsilon):
        super(Model, self).__init__()
        self.save_hyperparameters()
        # ADD BATCH NORMALIZATION
        # Convolutional layers
        # IN N,3,128,128
        self.conv3_32 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)
        self.conv32_32 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)
        # OUT N,16,128,128
        # POOLED N,16,64,64
        self.conv32_64 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.conv64_64 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)
        # OUT N,32,64,64
        # POOLED N,32,32,32
        self.conv64_128 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)
        self.conv128_128 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)
        # OUT N,64,32,32
        # POOLED N,128,16,16

        # Pooling layers
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # Fully connected layer
        self.fc1 = nn.Linear(128 * 16 * 16, 2048)
        self.fc2 = nn.Linear(2048, 2048)
        self.fc3 = nn.Linear(2048, num_classes)
        # Define the convolutional layers

        self.dropout50 = nn.Dropout(0.50)

        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.epsilon = epsilon
        self.weight_decay = 0.0001

        self.criterion = nn.CrossEntropyLoss()

        self.accuracy = torchmetrics.Accuracy(num_classes=2, average='macro', task='multiclass')

        self.test_transform = transforms.Compose([
            transforms.Resize((128, 128)),  # Resize images to 256x256
            transforms.ToTensor(),  # Convert images to PyTorch tensors
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images
        ])
        self.transform = transforms.Compose([
            transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),  # Randomly crops and resizes images to 224x224
            transforms.RandomHorizontalFlip(p=0.5),  # Randomly flips images horizontally
            transforms.RandomRotation(15),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
            transforms.ToTensor(),  # Convert images to PyTorch tensors
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images
        ])
        self.conf_matrix = ConfusionMatrix(task="multiclass", num_classes=num_classes)
        self.all_classes = ['galaxies', 'stars']
        self.apply(self._init_weights)

    def _init_weights(self, module):
        if isinstance(module, nn.Conv2d):
            init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='leaky_relu')
            if module.bias is not None:
                init.constant_(module.bias, 0)
        elif isinstance(module, nn.Linear):
            init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='leaky_relu')
            if module.bias is not None:
                init.constant_(module.bias, 0)

    def forward(self, image):
        image = F.leaky_relu(self.conv3_32(image))
        image = F.leaky_relu(self.conv32_32(image))
        image = F.leaky_relu(self.conv32_32(image))
        image = self.pool(image)
        image = F.leaky_relu(self.conv32_64(image))
        image = F.leaky_relu(self.conv64_64(image))
        image = F.leaky_relu(self.conv64_64(image))
        image = self.pool(image)
        image = F.leaky_relu(self.conv64_128(image))
        image = F.leaky_relu(self.conv128_128(image))
        image = F.leaky_relu(self.conv128_128(image))
        image = self.pool(image)  # Output is now (128, 25, 25)
        image = torch.flatten(image, 1)  # Flatten the output
        image = F.leaky_relu(self.fc1(image))
        image = self.dropout50(image)
        image = F.leaky_relu(self.fc2(image))
        image = self.dropout50(image)
        image = self.fc3(image)
        return image

    def training_step(self, batch, batch_idx):
        images, labels = batch
        predictions = self(images)  # Forward pass
        loss = self.criterion(predictions, labels)  # Compute the loss
        predicted_classes = torch.argmax(F.softmax(predictions, dim=1), dim=1)
        predictions_softmax = F.softmax(predictions, dim=1)
        self.accuracy(predictions_softmax, labels)
        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
        self.log('train_acc', self.accuracy, on_step=True, on_epoch=True, prog_bar=True)
        return loss  # Returning the loss for backpropagation

    def validation_step(self, batch, batch_idx):
        images, labels = batch
        predictions = self(images)
        loss = self.criterion(predictions, labels)
        predicted_classes = torch.argmax(F.softmax(predictions, dim=1), dim=1)
        predictions_softmax = F.softmax(predictions, dim=1)
        self.conf_matrix(predictions, labels)
        self.accuracy(predictions_softmax, labels)
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', self.accuracy, prog_bar=True)
        return loss

    def on_validation_epoch_end(self):
        confmat = self.conf_matrix.compute().cpu().numpy()
        # Compute per-class accuracy from the confusion matrix
        per_class_accuracy = confmat.diagonal() / confmat.sum(axis=1)
        for idx, acc in enumerate(per_class_accuracy):
            self.log(f'class_{self.all_classes[idx]}_accuracy', acc, prog_bar=True)
        self.conf_matrix.reset()

    def test_step(self, batch, batch_idx):
        images, labels = batch
        predictions = self(images)
        loss = self.criterion(predictions, labels)
        predicted_classes = torch.argmax(F.softmax(predictions, dim=1), dim=1)
        predictions_softmax = F.softmax(predictions, dim=1)
        self.accuracy(predictions_softmax, labels)
        real_step_acc = (labels == predicted_classes).sum() / self.batch_size
        self.conf_matrix(predictions, labels)
        self.log('test_loss', loss, prog_bar=True)
        self.log('real_test_acc', real_step_acc, prog_bar=True)
        self.log('test_acc', self.accuracy, prog_bar=True)
        return loss

    def on_test_epoch_end(self):
        confmat = self.conf_matrix.compute().cpu().numpy()
        # Compute per-class accuracy from the confusion matrix
        per_class_accuracy = confmat.diagonal() / confmat.sum(axis=1)
        for idx, acc in enumerate(per_class_accuracy):
            self.log(f'class_{self.all_classes[idx]}_accuracy', acc)
        self.conf_matrix.reset()

    def configure_optimizers(self):
        # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, eps=self.epsilon,
        #                              weight_decay=self.weight_decay)
        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.9,
                                    weight_decay=self.weight_decay)
        return optimizer

    def train_dataloader(self):
        # Set up and return the training DataLoader
        filepath_train = "data/train"

        train_dataset = datasets.ImageFolder(root=filepath_train, transform=self.transform)
        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=16)

        return train_loader

    def test_dataloader(self):
        # Set up and return the training DataLoader
        filepath_train = "data/test"

        test_dataset = datasets.ImageFolder(root=filepath_train, transform=self.test_transform)
        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=16)

        return test_loader

    def val_dataloader(self):
        # Set up and return the validation DataLoader
        filepath_train = "data/validate"

        val_dataset = datasets.ImageFolder(root=filepath_train, transform=self.test_transform)
        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=16)

        return val_loader

# HyperParams
output_size_of_pooling = 3
learning_rate = 0.001
batch_size = 64
torch.set_num_threads(16)
num_classes = 2
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
epsilon = 0.001


filepath_train = "data/train"
filepath_test = "data/test"


def count_jpg_files(directory):
    jpg_files = get_all_jpg_files_in(directory)
    # Return the count of JPG files
    return len(jpg_files)


def get_all_jpg_files_in(directory):
    # List all files in the directory
    files = os.listdir(directory)
    # Filter files to include only JPG files
    jpg_files = [file for file in files if file.lower().endswith('.jpg')]
    return jpg_files


transform = transforms.Compose([
    transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),  # Randomly crops and resizes images to 224x224
    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flips images horizontally
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),  # Convert images to PyTorch tensors
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images
])
train_dataset = datasets.ImageFolder(root=filepath_train, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=16)

# Check some dataset properties
print(f"Number of classes: {len(train_dataset.classes)}")
print(f"Class names: {train_dataset.classes}")
print(f"Number of images: {len(train_dataset)}")


def imshow(img, mean=mean, std=std):
    # Denormalize the image
    img = img.numpy().transpose((1, 2, 0))  # Change dimensions to (H,W,C)
    img = std * img + mean  # Denormalize
    img = np.clip(img, 0, 1)  # Clip to range [0, 1]
    plt.imshow(img)
    plt.axis('off')  # Turn off axis numbers and ticks


# Get a batch of images
dataiter = iter(train_loader)
images, labels = next(dataiter)


model = Model.load_from_checkpoint(checkpoint_path="lightning_logs/version_2/checkpoints/88.7%epoch=32-step=8250.ckpt",
                                   batch_size=batch_size,
                                   learning_rate=learning_rate,
                                   num_classes=num_classes,
                                   output_size_of_pooling=output_size_of_pooling)

import matplotlib.pyplot as plt
import numpy as np


def plot_large_weights_distribution(model, threshold=1.0):
    """
    Plot the distribution of weights for each layer in the given model, focusing on weights above a certain threshold.

    Parameters:
    model: torch.nn.Module
        The PyTorch model whose weights are to be plotted.
    threshold: float
        The threshold above which weights are considered 'large'. Default is 1.0.
    """
    for name, param in model.named_parameters():
        if 'weight' in name:
            # Convert weights to numpy array and flatten
            weights = param.data.cpu().numpy().flatten()

            # Find large weights
            large_weights = weights[weights > threshold]

            # Plot the distribution of all weights
            plt.figure(figsize=(6, 4))
            plt.hist(weights, bins=50, color='blue', alpha=0.6, label='All weights')
            plt.hist(large_weights, bins=50, color='red', alpha=0.6, label=f'Weights > {threshold}')
            plt.title(f'Weight Distribution of {name}')
            plt.xlabel('Weight value')
            plt.ylabel('Frequency')
            plt.grid(True)
            plt.legend()
            plt.show()


# Assuming `model` is your PyTorch model instance
plot_large_weights_distribution(model, threshold=1.0)

trainer = L.Trainer(max_epochs=200)

# trainer.fit(model)
trainer.test(model)


# #
#
#


# Define a function to display images and their predicted labels
def display_predictions(model, dataloader, num_images=6):
    model.eval()  # Set the model to evaluation mode
    images_so_far = 0
    fig = plt.figure(figsize=(10, 10))

    with torch.no_grad():  # No need to compute gradients
        for i, (images, labels) in enumerate(dataloader):
            outputs = model(images)
            _, preds = torch.max(outputs, 1)  # Get the index of the max log-probability
            for j in range(images.size(0)):
                images_so_far += 1
                ax = plt.subplot(num_images // 2, 2, images_so_far)
                ax.axis('off')
                ax.set_title(
                    f'Real:{dataloader.dataset.classes[labels[j]]} Predicted: {dataloader.dataset.classes[preds[j]]}')
                imshow(images[j])

                if images_so_far == num_images:
                    return


filepath_validate = "data/validate"
test_transform = transforms.Compose([
            transforms.Resize((128, 128)),  # Resize images to 256x256
            transforms.ToTensor(),  # Convert images to PyTorch tensors
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images
        ])
val_dataset = datasets.ImageFolder(root=filepath_validate, transform=test_transform)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=16)
#
# # Assuming `val_loader` is your validation DataLoader
for i in range(8):
    display_predictions(model, val_loader, num_images=6)
plt.show()

filepath_hand_test="data/hand_test"
test_transform = transforms.Compose([
            transforms.Resize((128, 128)),  # Resize images to 256x256
            transforms.ToTensor(),  # Convert images to PyTorch tensors
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images
        ])
val_dataset = datasets.ImageFolder(root=filepath_hand_test, transform=test_transform)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=16)
#
# # Assuming `val_loader` is your validation DataLoader
for i in range(1):
    display_predictions(model, val_loader, num_images=6)
plt.show()
